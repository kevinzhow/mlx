#version 450

// Stage 1 for decode SDPA split-k:
// each workgroup computes one (row, split) partial tuple:
// - partial row max (m)
// - partial row exp sum (l)
// - partial unnormalized weighted value sum (o)
layout(local_size_x = 64, local_size_y = 1, local_size_z = 1) in;

layout(set = 0, binding = 0) readonly buffer QBuffer {
  uint words[];
} q_buffer;

layout(set = 0, binding = 1) readonly buffer KBuffer {
  uint words[];
} k_buffer;

layout(set = 0, binding = 2) readonly buffer VBuffer {
  uint words[];
} v_buffer;

layout(set = 0, binding = 3) buffer PartialOBuffer {
  float values[];
} partial_o_buffer;

layout(set = 0, binding = 4) buffer PartialMBuffer {
  float values[];
} partial_m_buffer;

layout(set = 0, binding = 5) buffer PartialLBuffer {
  float values[];
} partial_l_buffer;

layout(set = 0, binding = 6) readonly buffer MaskBuffer {
  uint words[];
} mask_buffer;

layout(push_constant) uniform PushConstants {
  uint batch_size;
  uint n_q_heads;
  uint n_kv_heads;
  uint q_len;
  uint k_len;
  uint qk_dim;
  uint v_dim;
  uint k_head_stride;
  uint k_seq_stride;
  uint v_head_stride;
  uint v_seq_stride;
  uint mask_mode;
  uint mask_batch_stride;
  uint mask_head_stride;
  uint mask_q_stride;
  uint mask_k_stride;
  uint causal;
  uint split_k;
  float scale;
} params;

const uint WG_SIZE = 64u;
const float NEG_LARGE = -3.4028235e38;

shared float dot_partial[WG_SIZE];
shared float max_logit_sh;
shared float weight_sh;
shared float denom_sh;
shared float accum_sh[256];

float bf16_to_f32(uint bf16_bits) {
  return uintBitsToFloat((bf16_bits & 0xFFFFu) << 16u);
}

float load_q(uint elem_idx) {
  uint packed = q_buffer.words[elem_idx >> 1u];
  uint bf16_bits = ((elem_idx & 1u) == 0u) ? (packed & 0xFFFFu)
                                           : (packed >> 16u);
  return bf16_to_f32(bf16_bits);
}

float load_k(uint elem_idx) {
  uint packed = k_buffer.words[elem_idx >> 1u];
  uint bf16_bits = ((elem_idx & 1u) == 0u) ? (packed & 0xFFFFu)
                                           : (packed >> 16u);
  return bf16_to_f32(bf16_bits);
}

float load_v(uint elem_idx) {
  uint packed = v_buffer.words[elem_idx >> 1u];
  uint bf16_bits = ((elem_idx & 1u) == 0u) ? (packed & 0xFFFFu)
                                           : (packed >> 16u);
  return bf16_to_f32(bf16_bits);
}

float load_mask_add(uint elem_idx) {
  uint packed = mask_buffer.words[elem_idx >> 1u];
  uint bf16_bits = ((elem_idx & 1u) == 0u) ? (packed & 0xFFFFu)
                                           : (packed >> 16u);
  return bf16_to_f32(bf16_bits);
}

bool load_mask_bool(uint elem_idx) {
  return mask_buffer.words[elem_idx] != 0u;
}

float masked_logit(float dot, uint q_pos, uint k_pos, uint mask_base, out bool valid) {
  valid = true;
  float logit = dot * params.scale;

  if (params.causal != 0u) {
    int causal_limit = int(q_pos) + int(params.k_len) - int(params.q_len);
    if (int(k_pos) > causal_limit) {
      valid = false;
      return 0.0;
    }
  }

  if (params.mask_mode == 1u) {
    logit += load_mask_add(mask_base + k_pos * params.mask_k_stride);
    if (isinf(logit) && logit < 0.0) {
      valid = false;
      return 0.0;
    }
  } else if (params.mask_mode == 2u) {
    if (!load_mask_bool(mask_base + k_pos * params.mask_k_stride)) {
      valid = false;
      return 0.0;
    }
  }

  return logit;
}

void main() {
  uint gid = gl_WorkGroupID.x;
  uint lane = gl_LocalInvocationID.x;

  uint n_rows = params.batch_size * params.n_q_heads * params.q_len;
  uint total = n_rows * params.split_k;
  if (gid >= total || params.split_k == 0u || params.q_len == 0u ||
      params.v_dim == 0u ||
      params.v_dim > 256u || params.qk_dim == 0u || params.k_len == 0u ||
      params.n_kv_heads == 0u) {
    return;
  }

  uint rowq = gid / params.split_k;
  uint part = gid % params.split_k;
  uint row = rowq / params.q_len;
  uint q_pos = rowq % params.q_len;

  uint b = row / params.n_q_heads;
  uint hq = row % params.n_q_heads;
  uint repeats = params.n_q_heads / params.n_kv_heads;
  uint hkv = hq / repeats;

  uint q_base = (((b * params.n_q_heads) + hq) * params.q_len + q_pos) * params.qk_dim;
  uint kvh = (b * params.n_kv_heads) + hkv;
  uint k_head_base = kvh * params.k_head_stride;
  uint v_head_base = kvh * params.v_head_stride;
  uint mask_base = b * params.mask_batch_stride +
      hq * params.mask_head_stride + q_pos * params.mask_q_stride;

  uint chunk = (params.k_len + params.split_k - 1u) / params.split_k;
  uint start_t = part * chunk;
  uint end_t = min(params.k_len, start_t + chunk);

  uint partial_idx = rowq * params.split_k + part;
  uint partial_o_base = partial_idx * params.v_dim;

  if (lane == 0u) {
    max_logit_sh = NEG_LARGE;
    denom_sh = 0.0;
  }
  for (uint dv = lane; dv < params.v_dim; dv += WG_SIZE) {
    accum_sh[dv] = 0.0;
  }
  barrier();

  if (start_t >= end_t) {
    if (lane == 0u) {
      partial_m_buffer.values[partial_idx] = NEG_LARGE;
      partial_l_buffer.values[partial_idx] = 0.0;
    }
    for (uint dv = lane; dv < params.v_dim; dv += WG_SIZE) {
      partial_o_buffer.values[partial_o_base + dv] = 0.0;
    }
    return;
  }

  // Pass 1: row max in this split.
  for (uint t = start_t; t < end_t; ++t) {
    uint k_base = k_head_base + t * params.k_seq_stride;
    float partial = 0.0;
    for (uint d = lane; d < params.qk_dim; d += WG_SIZE) {
      partial += load_q(q_base + d) * load_k(k_base + d);
    }
    dot_partial[lane] = partial;
    barrier();

    for (uint stride = WG_SIZE / 2u; stride > 0u; stride >>= 1u) {
      if (lane < stride) {
        dot_partial[lane] += dot_partial[lane + stride];
      }
      barrier();
    }

    if (lane == 0u) {
      bool valid = false;
      float logit = masked_logit(dot_partial[0], q_pos, t, mask_base, valid);
      if (valid) {
        max_logit_sh = max(max_logit_sh, logit);
      }
    }
    barrier();
  }

  // Pass 2: exp sum + weighted V sum in this split.
  for (uint t = start_t; t < end_t; ++t) {
    uint k_base = k_head_base + t * params.k_seq_stride;
    float partial = 0.0;
    for (uint d = lane; d < params.qk_dim; d += WG_SIZE) {
      partial += load_q(q_base + d) * load_k(k_base + d);
    }
    dot_partial[lane] = partial;
    barrier();

    for (uint stride = WG_SIZE / 2u; stride > 0u; stride >>= 1u) {
      if (lane < stride) {
        dot_partial[lane] += dot_partial[lane + stride];
      }
      barrier();
    }

    if (lane == 0u) {
      bool valid = false;
      float logit = masked_logit(dot_partial[0], q_pos, t, mask_base, valid);
      if (!valid || max_logit_sh <= -3.0e38) {
        weight_sh = 0.0;
      } else {
        weight_sh = exp(logit - max_logit_sh);
        denom_sh += weight_sh;
      }
    }
    barrier();

    uint v_base = v_head_base + t * params.v_seq_stride;
    float w = weight_sh;
    for (uint dv = lane; dv < params.v_dim; dv += WG_SIZE) {
      accum_sh[dv] += w * load_v(v_base + dv);
    }
    barrier();
  }

  if (lane == 0u) {
    partial_m_buffer.values[partial_idx] = max_logit_sh;
    partial_l_buffer.values[partial_idx] = denom_sh;
  }
  for (uint dv = lane; dv < params.v_dim; dv += WG_SIZE) {
    partial_o_buffer.values[partial_o_base + dv] = accum_sh[dv];
  }
}
