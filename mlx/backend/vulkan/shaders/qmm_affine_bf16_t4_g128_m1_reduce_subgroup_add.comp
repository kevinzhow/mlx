#version 450
#extension GL_KHR_shader_subgroup_basic : require
#extension GL_KHR_shader_subgroup_arithmetic : require

// Decode-specialized fused QMM(+residual add) kernel for rows==1.
// Uses subgroup reduction and supports dynamic groups_per_col (<=256).
layout(local_size_x = 64, local_size_y = 1, local_size_z = 1) in;

layout(set = 0, binding = 0) readonly buffer XBuffer {
  uint words[];
} x_buffer;

layout(set = 0, binding = 1) readonly buffer WBuffer {
  uint words[];
} w_buffer;

layout(set = 0, binding = 2) readonly buffer ScaleBuffer {
  uint words[];
} scale_buffer;

layout(set = 0, binding = 3) readonly buffer BiasBuffer {
  uint words[];
} bias_buffer;

layout(set = 0, binding = 4) readonly buffer ResidualBuffer {
  uint words[];
} residual_buffer;

layout(set = 0, binding = 5) writeonly buffer OutBuffer {
  uint words[];
} out_buffer;

layout(push_constant) uniform PushConstants {
  uint out_elems;
  uint n;
  uint k;
  uint groups_per_col;
  uint w_words_per_col;
} params;

const uint MAX_GROUPS_PER_COL = 256u;
shared float subgroup_reduce0[64];
shared float subgroup_reduce1[64];
shared float scale0_cache[MAX_GROUPS_PER_COL];
shared float bias0_cache[MAX_GROUPS_PER_COL];
shared float scale1_cache[MAX_GROUPS_PER_COL];
shared float bias1_cache[MAX_GROUPS_PER_COL];

float bf16_to_f32(uint bf16_bits) {
  return uintBitsToFloat((bf16_bits & 0xFFFFu) << 16u);
}

uint f32_to_bf16(float value) {
  uint bits = floatBitsToUint(value);
  uint lsb = (bits >> 16u) & 1u;
  uint rounding_bias = 0x7FFFu + lsb;
  return (bits + rounding_bias) >> 16u;
}

float load_bf16_from_packed(uint packed, uint elem_idx) {
  uint bf16_bits = ((elem_idx & 1u) == 0u) ? (packed & 0xFFFFu)
                                           : (packed >> 16u);
  return bf16_to_f32(bf16_bits);
}

float load_residual_elem(uint elem_idx) {
  return load_bf16_from_packed(residual_buffer.words[elem_idx >> 1u], elem_idx);
}

void main() {
  const uint out_word_idx = gl_WorkGroupID.x;
  const uint lane = gl_LocalInvocationID.x;
  const uint out_words = (params.out_elems + 1u) / 2u;
  if (out_word_idx >= out_words) {
    return;
  }

  const uint out_elem_0 = out_word_idx * 2u;
  const uint out_elem_1 = out_elem_0 + 1u;
  const bool has_out_1 = out_elem_1 < params.out_elems;

  float partial0 = 0.0;
  float partial1 = 0.0;

  for (uint g = lane; g < params.groups_per_col; g += 64u) {
    const uint scale_bias_idx0 = out_elem_0 * params.groups_per_col + g;
    scale0_cache[g] = load_bf16_from_packed(
        scale_buffer.words[scale_bias_idx0 >> 1u], scale_bias_idx0);
    bias0_cache[g] = load_bf16_from_packed(
        bias_buffer.words[scale_bias_idx0 >> 1u], scale_bias_idx0);
    if (has_out_1) {
      const uint scale_bias_idx1 = out_elem_1 * params.groups_per_col + g;
      scale1_cache[g] = load_bf16_from_packed(
          scale_buffer.words[scale_bias_idx1 >> 1u], scale_bias_idx1);
      bias1_cache[g] = load_bf16_from_packed(
          bias_buffer.words[scale_bias_idx1 >> 1u], scale_bias_idx1);
    }
  }
  barrier();

  const uint total_units = params.groups_per_col * 16u;
  const uint group_size = 128u;

  for (uint unit = lane; unit < total_units; unit += 64u) {
    const uint g = unit >> 4u;
    const uint ww = unit & 0xFu;

    const float scale0 = scale0_cache[g];
    const float bias0 = bias0_cache[g];
    const float scale1 = has_out_1 ? scale1_cache[g] : 0.0;
    const float bias1 = has_out_1 ? bias1_cache[g] : 0.0;

    const uint w_word_idx0 = out_elem_0 * params.w_words_per_col + g * 16u + ww;
    const uint wi0 = w_buffer.words[w_word_idx0];
    uint wi1 = 0u;
    if (has_out_1) {
      const uint w_word_idx1 =
          out_elem_1 * params.w_words_per_col + g * 16u + ww;
      wi1 = w_buffer.words[w_word_idx1];
    }

    const uint x_group_word_base = (g * group_size) >> 1u;
    const uint x_word_base = x_group_word_base + ww * 4u;

    for (uint t = 0u; t < 4u; ++t) {
      const uint x_packed = x_buffer.words[x_word_base + t];
      const uint q_idx = t * 2u;
      const float q0 = float((wi0 >> (q_idx * 4u)) & 0xFu);
      const float q1 = float((wi0 >> ((q_idx + 1u) * 4u)) & 0xFu);
      const float x0 = load_bf16_from_packed(x_packed, 0u);
      const float x1 = load_bf16_from_packed(x_packed, 1u);
      partial0 += x0 * (scale0 * q0 + bias0);
      partial0 += x1 * (scale0 * q1 + bias0);

      if (has_out_1) {
        const float q10 = float((wi1 >> (q_idx * 4u)) & 0xFu);
        const float q11 = float((wi1 >> ((q_idx + 1u) * 4u)) & 0xFu);
        partial1 += x0 * (scale1 * q10 + bias1);
        partial1 += x1 * (scale1 * q11 + bias1);
      }
    }
  }

  const float subgroup_sum0 = subgroupAdd(partial0);
  const float subgroup_sum1 = subgroupAdd(partial1);
  if (gl_NumSubgroups == 1u) {
    if (gl_SubgroupInvocationID == 0u) {
      const float fused0 = subgroup_sum0 + load_residual_elem(out_elem_0);
      uint packed = f32_to_bf16(fused0) & 0xFFFFu;
      if (has_out_1) {
        const float fused1 = subgroup_sum1 + load_residual_elem(out_elem_1);
        packed |= (f32_to_bf16(fused1) & 0xFFFFu) << 16u;
      }
      out_buffer.words[out_word_idx] = packed;
    }
    return;
  }

  if (gl_SubgroupInvocationID == 0u) {
    subgroup_reduce0[gl_SubgroupID] = subgroup_sum0;
    subgroup_reduce1[gl_SubgroupID] = subgroup_sum1;
  }
  barrier();

  if (gl_SubgroupID == 0u) {
    const float seed0 = (lane < gl_NumSubgroups) ? subgroup_reduce0[lane] : 0.0;
    const float seed1 = (lane < gl_NumSubgroups) ? subgroup_reduce1[lane] : 0.0;
    const float total0 = subgroupAdd(seed0);
    const float total1 = subgroupAdd(seed1);
    if (gl_SubgroupInvocationID == 0u) {
      const float fused0 = total0 + load_residual_elem(out_elem_0);
      uint packed = f32_to_bf16(fused0) & 0xFFFFu;
      if (has_out_1) {
        const float fused1 = total1 + load_residual_elem(out_elem_1);
        packed |= (f32_to_bf16(fused1) & 0xFFFFu) << 16u;
      }
      out_buffer.words[out_word_idx] = packed;
    }
  }
}
